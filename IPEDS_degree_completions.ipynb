{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting IPEDS Completions Data into Panels for Institution-Level Trends Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The U.S. Department of Education's Integrated Postseconday Educational Data System (IPEDS) is a rich source of public data for education researchers, labor economists, HR analysts, or anyone interested in the supply of skilled labor.  In particular, the data on the number of degrees awarded by each educational institution (a.k.a. degree \"completions\") are very useful for anyone who wants to understand the availability of talent with a particular academic background, and how that varies by geographic location, diversity factors (such as ethnicity or gender), and time. \n",
    "\n",
    "It's easy enough to download the IPEDS completions data for an individual year.  But what if we want to analyze institution-level changes over time?  Unfortunately, IPEDS has made several changes to its reporting format over the years, including:\n",
    "* Changes in both file and field naming conventions,\n",
    "* Differences in which fields are included in which file,\n",
    "* Inconsistencies in the order of fields across files, and\n",
    "* Changes to the encoding system of the [Classification of Instructional Programs (CIP)](https://nces.ed.gov/ipeds/cipcode/), which indicates the academic program for which a degree was awarded.\n",
    "\n",
    "The first half of this iPython notebook contains a script that: \n",
    "* Downloads the completions data for every fifth year since 1980 (i.e. 1980, 1985,...2015),\n",
    "* Standardizes the various file- and field-level differences across the files, and then\n",
    "* Merges those individual files into one Pandas dataframe with a (year x institution x academic program) panel structure.\n",
    "\n",
    "The second half of this notebook demonstrates the type of analyses that can be performed on these data.  It uses computer science and related disciplines (CIP codes under category #11) as an example.\n",
    "\n",
    "### A few notes of caution/interest:\n",
    "* The mechanism used by the script to download and extract the files relies on iPython \"magic\" to invoke a bash command.  It won't work if run in a \"vanilla\" Python environment, and won't work on a Windows box.\n",
    "* Just to be super-explicit about this:  The script will download a bunch of files and put them on your hard drive, in whatever working directory you've set iPython to use.  On my home internet connection, the downloads take about two minutes. \n",
    "* For now, the scope is limited to gender-based breakouts of degree completions (i.e. men vs. women).  Ethnicity-based breakouts are also available in the raw data, and I may add them in the future.\n",
    "* If all you're interested in are national-level aggregations of the data, this is overkill.  The [Digest of Education Statistics](https://nces.ed.gov/Programs/digest/) contains tables of such aggregates.\n",
    "\n",
    "### To-dos for later:\n",
    "* The dataframes created by this script contain CIP codes.  Mapping those to program descriptions is trivial, but due to the ways the CIP has changed over the years, a bit laborious.  Since the analysis is focused on one CIP category, I'm not going to worry about it right now.\n",
    "* Some analyses may benefit from looking at the data annually (rather than every five years).  Again, this is trivial, but somewhat laborious -- and it uses more RAM and processing time.\n",
    "* The example analysis below revealed some suspicious looking data for the year 1980.  The integrity of this file should be inspected more thoroughly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  327k  100  327k    0     0   248k      0  0:00:01  0:00:01 --:--:--  248k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  537k  100  537k    0     0   118k      0  0:00:04  0:00:04 --:--:--  128k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  649k  100  649k    0     0   222k      0  0:00:02  0:00:02 --:--:--  222k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1835k  100 1835k    0     0   202k      0  0:00:09  0:00:09 --:--:--  177k   0     0   197k      0  0:00:09  0:00:06  0:00:03  194k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1979k  100 1979k    0     0   297k      0  0:00:06  0:00:06 --:--:--  331k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 3475k  100 3475k    0     0   182k      0  0:00:19  0:00:19 --:--:--  167k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 10.9M  100 10.9M    0     0   132k      0  0:01:24  0:01:24 --:--:--  160k8k      0  0:01:15  0:00:13  0:01:02  157k\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 8699k  100 8699k    0     0   153k      0  0:00:56  0:00:56 --:--:--  126k00:55  0:00:33  0:00:22  149k\n"
     ]
    }
   ],
   "source": [
    "url_stub = 'https://nces.ed.gov/ipeds/datacenter/data/'\n",
    "\n",
    "# We want the completions file for each year divisible by 5 since 1980.\n",
    "years = [year for year in range(1980, 2016, 5)]\n",
    "\n",
    "# The first four files don't have a regular pattern to the filenames...\n",
    "file_stubs = ['c1980_4ormore_cip', 'c1985_cip', 'c8990cip', 'c9495_a']\n",
    "\n",
    "# ...but the last four do.\n",
    "file_stubs += ['c' + str(year) + '_a' for year in years[-4:]]\n",
    "\n",
    "# Now we get each file, unzip it, and save the csv to the working directory\n",
    "for f in file_stubs:\n",
    "    request = url_stub + f + '.zip'\n",
    "    !curl $request | tar -x         # bash command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the zip files we unpacked have two versions of the data -- \n",
    "# an original version and a revised version (designated with \n",
    "# _rv at the end of the filename).\n",
    "\n",
    "ls = !ls   # bash command, equivalent to os.listdir()\n",
    "\n",
    "for i, f in enumerate(file_stubs):\n",
    "    original_filename = f + '.csv'\n",
    "    revised_filename = f + '_rv.csv'\n",
    "    \n",
    "    if revised_filename in ls:\n",
    "        !rm $original_filename       # cleans up the local directory\n",
    "        file_stubs[i] = f + '_rv'    # ensures our import in the next chunk will work\n",
    "\n",
    "filenames = [f + '.csv' for f in file_stubs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in each csv as a pandas dataframe \n",
    "# and conform them to a common format\n",
    "\n",
    "pre2006_cols = ['unitid', 'cipcode', 'awlevel', 'crace15', 'crace16']\n",
    "post2006_cols = ['UNITID', 'CIPCODE', 'AWLEVEL', 'CTOTALM', 'CTOTALW']\n",
    "master_cols = [col.lower() for col in post2006_cols]\n",
    "dfs_dict = {}\n",
    "\n",
    "for (year, filename) in zip(years, filenames):         \n",
    "    # for now, we need to preserve the leading zeroes in the CIP codes\n",
    "    df = pd.read_csv(filename, dtype = {'cipcode': str, 'CIPCODE': str})\n",
    "    \n",
    "    # drop excess columns and standardize order\n",
    "    if year < 2006:\n",
    "        df = df.reindex(columns= pre2006_cols)\n",
    "    else:\n",
    "        df = df.reindex(columns= post2006_cols)\n",
    "    \n",
    "    # standardize column naming across all dfs\n",
    "    df.columns = master_cols\n",
    "    \n",
    "    # we need to keep track of year when we concatenate all the dfs\n",
    "    df.insert(0, 'year', year)  \n",
    "    \n",
    "    dfs_dict[year] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69719 entries, 0 to 69718\n",
      "Data columns (total 6 columns):\n",
      "year       69719 non-null int64\n",
      "unitid     69719 non-null int64\n",
      "cipcode    69719 non-null object\n",
      "awlevel    69719 non-null int64\n",
      "ctotalm    69719 non-null int64\n",
      "ctotalw    69719 non-null int64\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 3.2+ MB\n",
      "None\n",
      "   year  unitid cipcode  awlevel  ctotalm  ctotalw\n",
      "0  1980  100654   01020        5        6        0\n",
      "1  1980  100654   01030        5        2        0\n",
      "2  1980  100654   01080        5        0        2\n",
      "3  1980  100654   01120        5       14        0\n",
      "4  1980  100654   01130        5       10        1\n",
      "\n",
      "\n",
      "1985\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 116605 entries, 0 to 116604\n",
      "Data columns (total 6 columns):\n",
      "year       116605 non-null int64\n",
      "unitid     116605 non-null int64\n",
      "cipcode    116605 non-null object\n",
      "awlevel    116605 non-null int64\n",
      "ctotalm    116605 non-null int64\n",
      "ctotalw    116605 non-null int64\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 5.3+ MB\n",
      "None\n",
      "   year  unitid cipcode  awlevel  ctotalm  ctotalw\n",
      "0  1985  100654   10103        5        4        0\n",
      "1  1985  100654   20201        5        5        0\n",
      "2  1985  100654   20301        5        4        2\n",
      "3  1985  100654   20301        7        6        0\n",
      "4  1985  100654   20399        7        1        0\n",
      "\n",
      "\n",
      "1990\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 129518 entries, 0 to 129517\n",
      "Data columns (total 6 columns):\n",
      "year       129518 non-null int64\n",
      "unitid     129518 non-null int64\n",
      "cipcode    129518 non-null object\n",
      "awlevel    129518 non-null int64\n",
      "ctotalm    120446 non-null float64\n",
      "ctotalw    122523 non-null float64\n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 5.9+ MB\n",
      "None\n",
      "   year  unitid  cipcode  awlevel  ctotalm  ctotalw\n",
      "0  1990  100636  06.0402        3     66.0     19.0\n",
      "1  1990  100636  06.0701        3      7.0      2.0\n",
      "2  1990  100636  06.0704        3      2.0      0.0\n",
      "3  1990  100636  06.1201        3     84.0     23.0\n",
      "4  1990  100636  06.9999        3    128.0     73.0\n",
      "\n",
      "\n",
      "1995\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 163377 entries, 0 to 163376\n",
      "Data columns (total 6 columns):\n",
      "year       163377 non-null int64\n",
      "unitid     163377 non-null int64\n",
      "cipcode    163377 non-null object\n",
      "awlevel    163377 non-null int64\n",
      "ctotalm    163197 non-null float64\n",
      "ctotalw    163205 non-null float64\n",
      "dtypes: float64(2), int64(3), object(1)\n",
      "memory usage: 7.5+ MB\n",
      "None\n",
      "   year  unitid  cipcode  awlevel  ctotalm  ctotalw\n",
      "0  1995  100636  09.0501        3     16.0     19.0\n",
      "1  1995  100636  10.0199        3    351.0    122.0\n",
      "2  1995  100636  11.0301        3    101.0      9.0\n",
      "3  1995  100636  13.9999        3   1254.0    192.0\n",
      "4  1995  100636  15.0303        3   1292.0    147.0\n",
      "\n",
      "\n",
      "2000\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 173137 entries, 0 to 173136\n",
      "Data columns (total 6 columns):\n",
      "year       173137 non-null int64\n",
      "unitid     173137 non-null int64\n",
      "cipcode    173137 non-null object\n",
      "awlevel    173137 non-null int64\n",
      "ctotalm    173137 non-null int64\n",
      "ctotalw    173137 non-null int64\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 7.9+ MB\n",
      "None\n",
      "   year  unitid  cipcode  awlevel  ctotalm  ctotalw\n",
      "0  2000  100636  09.0501        3       14       12\n",
      "1  2000  100636  10.0199        3      331      129\n",
      "2  2000  100636  11.0101        3      116       10\n",
      "3  2000  100636  13.9999        3      826      150\n",
      "4  2000  100636  15.0303        3      860      102\n",
      "\n",
      "\n",
      "2005\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 230135 entries, 0 to 230134\n",
      "Data columns (total 6 columns):\n",
      "year       230135 non-null int64\n",
      "unitid     230135 non-null int64\n",
      "cipcode    230135 non-null object\n",
      "awlevel    230135 non-null int64\n",
      "ctotalm    230135 non-null int64\n",
      "ctotalw    230135 non-null int64\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 10.5+ MB\n",
      "None\n",
      "   year  unitid  cipcode  awlevel  ctotalm  ctotalw\n",
      "0  2005  100636  09.0999        3       16       12\n",
      "1  2005  100636  10.0105        3      371      208\n",
      "2  2005  100636  11.0101        3       91        6\n",
      "3  2005  100636  11.0401        3      687      249\n",
      "4  2005  100636  13.0499        3       84       76\n",
      "\n",
      "\n",
      "2010\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 265728 entries, 0 to 265727\n",
      "Data columns (total 6 columns):\n",
      "year       265728 non-null int64\n",
      "unitid     265728 non-null int64\n",
      "cipcode    265728 non-null object\n",
      "awlevel    265728 non-null int64\n",
      "ctotalm    265728 non-null int64\n",
      "ctotalw    265728 non-null int64\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 12.2+ MB\n",
      "None\n",
      "   year  unitid  cipcode  awlevel  ctotalm  ctotalw\n",
      "0  2010  100636  09.0999        3       36       25\n",
      "1  2010  100636  10.0105        3      706      293\n",
      "2  2010  100636  11.0101        3       65        3\n",
      "3  2010  100636  11.0401        3      751      197\n",
      "4  2010  100636  13.0499        3      152       77\n",
      "\n",
      "\n",
      "2015\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300263 entries, 0 to 300262\n",
      "Data columns (total 6 columns):\n",
      "year       300263 non-null int64\n",
      "unitid     300263 non-null int64\n",
      "cipcode    300263 non-null object\n",
      "awlevel    300263 non-null int64\n",
      "ctotalm    300263 non-null int64\n",
      "ctotalw    300263 non-null int64\n",
      "dtypes: int64(5), object(1)\n",
      "memory usage: 13.7+ MB\n",
      "None\n",
      "   year  unitid  cipcode  awlevel  ctotalm  ctotalw\n",
      "0  2015  100654  01.0000        5        3        0\n",
      "1  2015  100654  01.0901        5        0        4\n",
      "2  2015  100654  01.1001        5        2        7\n",
      "3  2015  100654  01.1001        7        2        5\n",
      "4  2015  100654  01.1001       17        1        1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check integrity of each df\n",
    "for year, df in dfs_dict.items():\n",
    "    print(year)\n",
    "    print(df.info())\n",
    "    print(df.head())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-1990 CIP codes were in a different format, let's \n",
    "# standardize them.  While we're at it, let's extract \n",
    "# the category from the first two digits.\n",
    "\n",
    "def modernize_cip(cipcode):\n",
    "    return cipcode[:2] + '.' + cipcode[2:]\n",
    "\n",
    "def cip_category(cipcode):\n",
    "    return np.int16(cipcode[:2])\n",
    "\n",
    "\n",
    "\n",
    "for year, df in dfs_dict.items():\n",
    "    if year < 1990:\n",
    "        df['cipcode'] = df['cipcode'].apply(modernize_cip)\n",
    "    df['cip_category'] = df['cipcode'].apply(cip_category)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1448482 entries, 0 to 300262\n",
      "Data columns (total 9 columns):\n",
      "year            1448482 non-null int64\n",
      "unitid          1448482 non-null int64\n",
      "cipcode         1448482 non-null object\n",
      "awlevel         1448482 non-null int64\n",
      "ctotalm         1439230 non-null float64\n",
      "ctotalw         1441315 non-null float64\n",
      "cip_category    1448482 non-null int64\n",
      "total           1432259 non-null float64\n",
      "pct_women       1243288 non-null float64\n",
      "dtypes: float64(4), int64(4), object(1)\n",
      "memory usage: 110.5+ MB\n",
      "None\n",
      "   year  unitid cipcode  awlevel  ctotalm  ctotalw  cip_category  total  \\\n",
      "0  1980  100654  01.020        5      6.0      0.0             1    6.0   \n",
      "1  1980  100654  01.030        5      2.0      0.0             1    2.0   \n",
      "2  1980  100654  01.080        5      0.0      2.0             1    2.0   \n",
      "3  1980  100654  01.120        5     14.0      0.0             1   14.0   \n",
      "4  1980  100654  01.130        5     10.0      1.0             1   11.0   \n",
      "\n",
      "    pct_women  \n",
      "0    0.000000  \n",
      "1    0.000000  \n",
      "2  100.000000  \n",
      "3    0.000000  \n",
      "4    9.090909  \n"
     ]
    }
   ],
   "source": [
    "completions_df = pd.concat(dfs_dict.values())\n",
    "completions_df['total'] = completions_df['ctotalm'] + completions_df['ctotalw']\n",
    "completions_df['pct_women'] = completions_df['ctotalw'] / completions_df['total'] * 100\n",
    "print(completions_df.info())\n",
    "print(completions_df.head())\n",
    "\n",
    "completions_df.to_csv('completions_1980_to_2015.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supplementing the data\n",
    "We now have a master completions dataframe that we can manipulate to get some insights into trends related to a particular institution or academic program. Two things that would help us in our analysis are:\n",
    "* A rollup of the total number of degrees granted by an institution in a given year, allowing us to calculate the percentage of all degrees awarded at that institution coming from a particular academic major.\n",
    "* Institutional characteristics, such as whether it's a public vs. private university.\n",
    "\n",
    "(There are a LOT of other things we could pull in from IPEDS to supplement the data, but let's concentrate on those three for now!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grand total degrees awarded by each institution, across \n",
    "# all fields and degree levels\n",
    "uni_degree_totals = pd.pivot_table(\n",
    "    completions_df,\n",
    "    index= ['year', 'unitid', 'awlevel'],\n",
    "    values= ['ctotalm', 'ctotalw', 'total'],\n",
    "    aggfunc= np.sum)\n",
    "\n",
    "uni_degree_totals.columns = ['uni_total_men', 'uni_total_women', 'uni_grand_total']\n",
    "\n",
    "\n",
    "# total bachelors degrees by institution, across all fields \n",
    "uni_bachelors_totals = uni_degree_totals.loc[\n",
    "    uni_degree_totals.index.get_level_values('awlevel') == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1065k  100 1065k    0     0   168k      0  0:00:06  0:00:06 --:--:--  159k   0   187k      0  0:00:05  0:00:01  0:00:04  187k\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 7647 entries, 100654 to 487728\n",
      "Data columns (total 6 columns):\n",
      "name         7647 non-null object\n",
      "state        7647 non-null object\n",
      "control      7647 non-null int64\n",
      "hbcu         7647 non-null int64\n",
      "longitude    7647 non-null object\n",
      "latitude     7647 non-null object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 418.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# The last thing we need before we can really analyze the data\n",
    "# is directory info about the universities, keyed on unitid.\n",
    "\n",
    "directory_request = url_stub + 'HD2015.zip'\n",
    "!curl $directory_request | tar -x\n",
    "uni_dir = pd.read_csv('HD2015.csv', encoding='latin-1')\n",
    "uni_dir.columns = [c.lower() for c in uni_dir.columns]\n",
    "\n",
    "# There's a lot of info in the directory, let's keep only fields of interest\n",
    "uni_dir = uni_dir[['unitid',   \n",
    "                  'instnm',    \n",
    "                  'stabbr',   # state abbrev. as string; FIPS code also available \n",
    "                  'control',  # see codebook below\n",
    "                  'hbcu',     # historically black indicator \n",
    "                  'longitud',  \n",
    "                  'latitude']].set_index('unitid')\n",
    "\n",
    "# mostly because 'longitud' is an annoying name for a field\n",
    "uni_dir.columns = ['name', 'state', 'control', 'hbcu', 'longitude', 'latitude']\n",
    "\n",
    "control_codes = {1: 'Public',\n",
    "                2: 'Private non-profit',\n",
    "                3: 'For-profit',\n",
    "                -3: 'Unknown'}\n",
    "\n",
    "hbcu_codes = {1: 'HBCU',\n",
    "             2: 'Not an HBCU'}\n",
    "\n",
    "print(uni_dir.info())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis:  Computer Science completions over time\n",
    "As an example of the type of analysis we can perform on these data, let's look now at bachelor's degrees awarded for computer science and related disciplines (CIP category #11). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     year  unitid cipcode  awlevel  ctotalm  ctotalw  cip_category  total  \\\n",
      "86   1980  101709  11.020        5      0.0      1.0            11    1.0   \n",
      "87   1980  101709  11.050        5      0.0      1.0            11    1.0   \n",
      "138  1980  100724  11.020        5      0.0      1.0            11    1.0   \n",
      "139  1980  100724  11.050        5      0.0      1.0            11    1.0   \n",
      "261  1980  100858  11.020        5      1.0     15.0            11   16.0   \n",
      "\n",
      "     pct_women  \n",
      "86      100.00  \n",
      "87      100.00  \n",
      "138     100.00  \n",
      "139     100.00  \n",
      "261      93.75  \n"
     ]
    }
   ],
   "source": [
    "cs_bachelors = completions_df[(completions_df['cip_category'] == 11) &\n",
    "                             (completions_df['awlevel'] == 5)]\n",
    "print(cs_bachelors.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bachelors_totals' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-2bb524012186>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mcs_by_uni\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cs_ba_men'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cs_ba_women'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cs_ba_total'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m cs_by_uni = pd.merge(cs_by_uni, bachelors_totals, \n\u001b[0m\u001b[1;32m     11\u001b[0m                      \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                      \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bachelors_totals' is not defined"
     ]
    }
   ],
   "source": [
    "# rollup to one entry per university per year\n",
    "\n",
    "cs_by_uni = pd.pivot_table(cs_bachelors, \n",
    "                            index=['year', 'unitid'],\n",
    "                            values=['ctotalm', 'ctotalw', 'total'],\n",
    "                            aggfunc=np.sum)\n",
    "\n",
    "cs_by_uni.columns = ['cs_ba_men', 'cs_ba_women', 'cs_ba_total']\n",
    "\n",
    "cs_by_uni = pd.merge(cs_by_uni, bachelors_totals, \n",
    "                     how='inner', \n",
    "                     left_index=True, \n",
    "                     right_index=True)\n",
    "\n",
    "cs_by_uni['cs_pct_women'] = cs_by_uni['cs_ba_women'] / cs_by_uni['cs_ba_total'] * 100\n",
    "cs_by_uni['ba_pct_cs'] = cs_by_uni['cs_ba_total'] / cs_by_uni['grand_total_ba'] * 100\n",
    "\n",
    "cs_by_uni = cs_by_uni.reset_index()\n",
    "\n",
    "cs_by_uni = cs_by_uni.sort_values(['year', 'cs_ba_total'], \n",
    "                                  ascending=[True, False])\n",
    "\n",
    "cs_by_uni = pd.merge(cs_by_uni, uni_dir, \n",
    "                     how='inner', \n",
    "                     left_on='unitid',\n",
    "                     right_index=True, \n",
    "                     validate='m:1')\n",
    "\n",
    "print(cs_by_uni.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of universities in the file.  For plotting purposes, we may want to constrain our analysis to institutions that were on the \"leaderboard\" for most degrees granted at some point over the time series, or perhaps to those that had the highest concentration of students majoring in CS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_unis_limit = 20\n",
    "top_unis_by_size = pd.DataFrame(columns=['unitid', 'name']).set_index('unitid')\n",
    "top_unis_by_pct = pd.DataFrame(columns=['unitid', 'name']).set_index('unitid')\n",
    "\n",
    "for year in years:\n",
    "    biggest_unis= cs_by_uni[cs_by_uni['year'] == year].sort_values(\n",
    "    'cs_ba_total', ascending=False).iloc[:top_unis_limit, [1,10]].set_index('unitid')\n",
    "    \n",
    "    top_unis_by_size = pd.concat([top_unis_by_size, biggest_unis]).drop_duplicates()\n",
    "    \n",
    "for year in years:\n",
    "    mostest_unis = cs_by_uni[cs_by_uni['year'] == year].sort_values(\n",
    "    'ba_pct_cs', ascending=False).iloc[:top_unis_limit, [1,10]].set_index('unitid')\n",
    "    \n",
    "    top_unis_by_pct = pd.concat([top_unis_by_pct, mostest_unis]).drop_duplicates()\n",
    "\n",
    "top_cs_unis = pd.concat([top_unis_by_size, top_unis_by_pct]).drop_duplicates()\n",
    "    \n",
    "print(top_unis_by_size)\n",
    "print(top_unis_by_pct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just scanning those two lists, the largest universities seem reasonable -- we can see several large public universities and technical institutes, as well as a few schools that have sizable distance learning programs (such as Saint Leo and the University of Phoenix).\n",
    "\n",
    "By contrast, the \"most concentrated\" list includes a lot of very small institutions.  Given that scoring in the top 20 for any of the years examined \"lands\" a school on this leaderboard, this measure is sensitive to one-off outliers in the dataset.\n",
    "\n",
    "So, let's focus our analysis on programs that scored on the \"largest\" leaderboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cs_unis_trend = cs_by_uni[cs_by_uni['unitid'].isin(top_unis_by_size.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some data questions!\n",
    "\n",
    "#### How has the size of university programs changed over time?\n",
    "At the level of individual universities, has the number of \"seats\" available in CS programs been growing over time?  One way to check our intuition on this is to look at the institution-level variation in degrees granted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,8))\n",
    "sns.boxplot(x='year', \n",
    "            y= 'cs_ba_total', \n",
    "           data=top_cs_unis_trend)\n",
    "plt.title(\"Institution-Level Variation in Number of CS \\nBachelor's Degrees Granted\")\n",
    "plt.text(x=1.5, \n",
    "         y=np.max(top_cs_unis_trend['cs_ba_total']), \n",
    "         s= 'Top' + str(len(top_cs_unis)) + ' Programs by Size Only')\n",
    "plt.ylabel(\"CS Bachelor's Degrees Granted\")\n",
    "plt.xlabel('Academic Year Ending In')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among these large-ish institutions, the median program got smaller from 1985 to 1995.  The average program started to get bigger after that (in conjunction with the 1990s dotcom boom), with the variation in individual program size widening as part of that trend.  The data from 2010 show that trend reversing -- a long-term impact of the dotcom bust in 2001, most likely -- while 2015 shows a dramatic increase in both the size of the median program and the variance in program size.\n",
    "\n",
    "From the bottoms of the whiskers, we can see that at least one institution graduated no or barely CS students in each of the years, indicating that the size of these programs may not be sustained year-over-year.  (We should keep in mind, however, that this doesn't necessarily mean that the institutions aren't teaching CS anymore -- it may indicate, for example, that CS instruction has been taken over by a department that reports under a different CIP category, such as Math or Electrical Engineering.)\n",
    "\n",
    "No individual program graduated more that 500 students prior to 2005, which is the first year in the data when we see really extreme outliers.  Inspection of those outliers shows they're all institutions that encapsulate large-scale multi-campus systems, and/or have large distance learning programs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cs_unis_trend.loc[top_cs_unis_trend['cs_ba_total'] > 500,\n",
    "                     ['year', 'unitid', 'name', 'cs_ba_total']].sort_values(\n",
    "    ['year', 'cs_ba_total'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How does the gender mix of CS programs vary on an institutional level?\n",
    "Similarly, we might ask whether the decline in the percentage of CS graduates who are women is a problem that spans across multiple institutions, or if it has been concentrated in a few institutions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize= (6,8))\n",
    "sns.boxplot(x='year', \n",
    "           y='cs_pct_women',\n",
    "           data=top_cs_unis_trend)\n",
    "plt.title(\"Institution-Level Variation in Percentage\\n of CS Bachelor's Degrees Granted to Women\")\n",
    "plt.text(x= 1.5,\n",
    "        y= 97.5,\n",
    "        s='Top ' + str(len(top_cs_unis)) + ' Programs by Size Only')\n",
    "plt.ylim(0, 100)\n",
    "plt.yticks(np.arange(0, 101, 10))\n",
    "plt.ylabel(\"% of CS Bachelor's Degrees\\n Granted to Women\")\n",
    "plt.xlabel('Academic Year Ending In')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals an overall declining trend in the average representation of women in CS programs at the institutional level, with only a handful of these programs showing more than 50% representation between 1985 and 2010, and none showing that much representation in 2015.  (And every year since 1995, at least one institution has seen zero women graduate with a CS degree!)\n",
    "\n",
    "The data from 1980 are extreme enough to warrant a double-check to make sure that there isn't a problem with the raw data file.  (The 1980 completions file is different from all that others in many ways, including the use of a not-quite-documented CIP.)  Beyond that, the institutions that awarded half or more of their CS degrees to women in years after 1980 are worth inspecting as outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cs_unis_trend.loc[(top_cs_unis_trend['cs_pct_women'] >= 50) &\n",
    "                      (top_cs_unis_trend['year'] > 1980),\n",
    "                     ['year', 'unitid', 'name', 'cs_ba_total', 'cs_pct_women']].sort_values(\n",
    "    ['year', 'cs_pct_women'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How has the size of individual programs changed over time?\n",
    "Or perhaps we'd like to know whether programs that were large in 1985 are still large today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flip the data around to a 1985 vs. 2015 comparison for each institution\n",
    "cs_data_1985 = top_cs_unis_trend.loc[\n",
    "    top_cs_unis_trend['year'] == 1985].iloc[\n",
    "    :, 1:].set_index('unitid')\n",
    "\n",
    "cs_data_2015 = top_cs_unis_trend.loc[\n",
    "    top_cs_unis_trend['year'] == 2015].iloc[\n",
    "    :, 1:10].set_index('unitid')\n",
    "\n",
    "cs_compare_85_15 = pd.merge(cs_data_1985, cs_data_2015, \n",
    "                                left_index=True,\n",
    "                                right_index=True, \n",
    "                                suffixes=('_85', '_15'))\n",
    "\n",
    "cs_compare_85_15['control'] = cs_compare_85_15['control'].apply(lambda c: control_codes[c])\n",
    "\n",
    "\n",
    "# plot it\n",
    "scale_limit = max(cs_compare_85_15['cs_ba_total_85'].max(), \n",
    "                 cs_compare_85_15['cs_ba_total_15'].max())\n",
    "scale_ticks = np.arange(0, scale_limit, 100)\n",
    "\n",
    "sns.pairplot(x_vars=['cs_ba_total_85'],\n",
    "        y_vars=['cs_ba_total_15'],\n",
    "        data= cs_compare_85_15,\n",
    "        hue='control',\n",
    "        size=8)\n",
    "plt.title('Size of Individual CS Programs in 1985 vs 2015')\n",
    "plt.text(x= scale_limit / 3,\n",
    "        y= scale_limit * 1.03,\n",
    "        s='Top ' + str(len(top_cs_unis)) + ' Programs by Size Only')\n",
    "plt.xticks(scale_ticks)\n",
    "plt.yticks(scale_ticks)\n",
    "plt.xlabel(\"# of CS bachelor's degrees awarded in 1985\")\n",
    "plt.ylabel(\"# of CS bachelor's degrees awarded in 2015\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print('Pearson correlation coefficient:', \n",
    "      (cs_compare_85_15.corr().loc['cs_ba_total_85', 'cs_ba_total_15']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there isn't a strong relationship here.  The correlation coefficient isn't significant, and there isn't a pattern to be found by focusing on only private or public institutions.\n",
    "\n",
    "Also notably, with the exception of Penn State -- which is the green dot at the top with 605 degrees awareded in 2015 -- none of the largest programs in recent years were established in 1985.  (Indeed, only one of the for-profit colleges on the biggest programs leaderboard was graduating CS majors back then.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Work in progress -- some extensions to make this more useful)\n",
    "\n",
    "The code below isn't necessary for the analysis presented here, but might be helpful for other analyses in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The analysis in this notebook is focused on award level #5 (bachelor's degrees).\n",
    "# For completeness, here's the codebook for the other levels.\n",
    "# Please note the post-2011 changes in how doctoral-level degrees are reported.\n",
    "\n",
    "award_levels = pd.DataFrame.from_dict({\n",
    "    1: \"Awards of less than 1 academic year below the bachelor's level\",\n",
    "    2: \"Awards of at least 1 but less than 2 academic years below the bachelor's level\",\n",
    "    3: \"Associate's degrees\",\n",
    "    4: \"Awards of at least 2 but less than 4 academic years below the bachelor's level\",\n",
    "    5: \"Bachelor's degrees\",\n",
    "    6: \"Postbaccalaureate certificates\",\n",
    "    7: \"Master's degrees\",\n",
    "    8: \"Post-Master's certificates\",\n",
    "    9: \"Doctor's degrees\",             # pre-2011 version of code #17 (i.e. Ph.D.)\n",
    "    10: \"First-professional degrees\",  # pre-2011 version of code #18\n",
    "    11: \"First-professional certificates (post-degree)\",  # not sure if this has a post-2011 equivalent\n",
    "    17: \"Doctor's degree - research/scholarship\",  # Ph.D. and similar\n",
    "    18: \"Doctor's degree - professional practice\", # Medical, law, and similar\n",
    "    19: \"Doctor's degree - other\"},\n",
    "    orient='index').reset_index()\n",
    "\n",
    "award_levels.columns = ['awlevel', 'description']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We did a rollup before that allowed us to look at the percentage of all degrees awarded by an institution that came from a given field.  \n",
    "\n",
    "A similar rollup of the total number of degrees granted in a given field in a given year -- allowing us to calculate the percentage \"share\" of that field's graduates that came from a particular institution -- might also be useful.  Depending on the specific analysis, we might want to do this at the field level (e.g. \"German Language & Literature\") or the category level (e.g. \"foreign languages and literatures\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# national total degrees in each field, across all degree levels\n",
    "field_degree_totals = pd.pivot_table(\n",
    "    completions_df, \n",
    "    index= ['year', 'cipcode', 'awlevel'],\n",
    "    values= ['ctotalm', 'ctotalw', 'total'],\n",
    "    aggfunc= np.sum)\n",
    "\n",
    "field_degree_totals.columns = ['field_total_men', 'field_total_women', \n",
    "                               'field_grand_total']\n",
    "\n",
    "\n",
    "# national total bachelors degrees by field\n",
    "field_bachelors_totals = field_degree_totals.loc[\n",
    "    field_degree_totals.index.get_level_values('awlevel') == 5]\n",
    "\n",
    "# national total degrees in each category, across all degree levels\n",
    "category_degree_totals = pd.pivot_table(\n",
    "    completions_df,\n",
    "    index= ['year', 'cip_category', 'awlevel'],\n",
    "    values= ['ctotalm', 'ctotalw', 'total'],\n",
    "    aggfunc= np.sum)\n",
    "\n",
    "category_degree_totals.columns = ['category_total_men', 'category_total_women', \n",
    "                                  'category_grand_total']\n",
    "\n",
    "\n",
    "# national total bachelors degrees by category\n",
    "category_bachelors_totals = category_degree_totals.loc[\n",
    "    category_degree_totals.index.get_level_values('awlevel') == 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_cs_by_year = category_bachelors_totals.loc[\n",
    "    category_bachelors_totals.index.get_level_values('cip_category') == 11]\n",
    "\n",
    "national_cs_by_year = national_cs_by_year.reset_index().loc[:, ['year', 'category_grand_total']]\n",
    "print(national_cs_by_year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
